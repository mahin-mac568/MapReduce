Kevlar: A Flexible Infrastructure for
Wide-Area Collaborative Applications
Qi Huang1,2 , Daniel A. Freedman2 , Ymir Vigfusson3 ,
Ken Birman2 , and Bo Peng2
1

SCTS & CGCL, Huazhong University of Science and Technology, Wuhan, China
2
Cornell University, Ithaca, New York, USA
3
IBM Research, Haifa, Israel

Abstract. While Web Services ensure interoperability and extensibility for networked applications, they also complicate the deployment of
highly collaborative systems, such as virtual reality environments and
massively multiplayer online games. Quite simply, such systems often
manifest a natural peer-to-peer structure. This conﬂicts with Web Services’ imposition of a client-server communication model, vectoring all
events through a data center and emerging as a performance bottleneck.
We design and implement the Kevlar system to alleviate such choke
points, using an overarching network-overlay structure to integrate central hosted content with peer-to-peer multicast. Kevlar leverages the
given storage and communication models that best match the respective
information: data most naturally retrieved from the cloud is managed
using hosted objects, while edge updates are transmitted directly peerto-peer using multicast. Here, we present the Kevlar architecture and
a series of carefully controlled experiments to evaluate our implementation. We demonstrate Kevlar’s successful and eﬃcient support of deployments across wide-area networks and its adaptivity and resilience to
ﬁrewalls, constrained network segments, and other peculiarities of local
network policy.
Keywords: Distributed systems, Overlay networks, Collaboration.

1

Introduction

The rapid evolution of the Internet has both produced and relied upon standards
for interoperability, enabling client systems to easily interact with sophisticated
data centers that host data, or create content. To leverage these standards,
more and more collaborative applications — virtual reality immersion environments [15], massively multiplayer online games [9], conference systems [10], and
other distributed tools — are now designed as Web Services [1], bouncing clientinitiated events oﬀ central shared data centers for relay to other clients. While
such an architecture functions acceptably in most settings, it performs and scales
poorly in particular environments: when the link between some set of clients and
the data center is congested, the latency on such a link is too high, or the servers
in the data center are overloaded.
Indranil Gupta and C. Mascolo (Eds.): Middleware 2010, LNCS 6452, pp. 148–168, 2010.
c IFIP International Federation for Information Processing 2010


Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

149

In prior work, we introduced a new method for combining standard Web
Services with peer-to-peer replication protocols. The Live Distributed Objects
(LO) platform [5,16] supports a simple drag-and-drop style of application development, similar to that used by non-programmers to design Web pages. The
resulting applications have an XML representation suitable for sharing: for example, via e-mail or through a networked ﬁle system. Each user who “opens”
an LO application activates the objects within some scope (for example, objects
visible from some location in a game environment), and each of the resulting object instances function as a replica of what is conceptually a distributed object.
We provide more details about our LO approach in Sect. 2, but, for now, note
that the design of LO starts to address the issues listed above.
However, LO lacks the type of protocol capable of fully exploiting this ﬂexibility, leaving open the question of whether our LO platform actually includes the
full range of needed mechanisms. In particular, although LO is eﬀective in enterprise network settings, the LO replication protocols are stymied by the many
barriers that arise in practical Internet deployments across wide-area networks
(WANs): performance variability, ﬁrewall interference, IP multicast (IPMC) policy non-uniformity, and more [14]. In the public Internet of 2010, point-to-point
TCP is often the only option to work reliably (and, even that, at times only in
one direction).
In this work, we introduce a substantially more capable wide-area multicast
solution embodied by our Kevlar system. Kevlar allows applications to create
multicast regions (“patches”), sewn together into a single spanning applicationlayer multicast structure, for content distribution or event-style notiﬁcations.
Kevlar is a decentralized and improved re-implementation of our prior work,
Quilt [12], restructured into a collection of Live Objects more robust to node
failures. Here, we also apply Kevlar to demonstrate a substantial application:
a search-and-rescue command-and-control system, useful in responding to environmental events such as hurricanes or earthquakes. We then undertake a careful
evaluation of our solution, accurately emulating potential deployment scenarios
and measuring associated event delivery latencies, data rates, and overhead.
Kevlar addresses a diﬃculty that arises from the need to construct applications that will run as a network of interconnected components and do so in
a way sensitive to their local runtime environments. Here, we focus on the selection of a multicast component from among a set of multicast protocols, each
specialized for a diﬀerent setting, but the potential applicability is broader. While
our research community has recognized that applications using component architectures should beneﬁt from such improved structure, the issue of adapting
such applications to match their runtime environments has received much less
attention. Our work shows that this is a solvable problem, and, through our
detailed evaluation, that the solutions are truly practical. The key enabler is the
Kevlar platform architecture: it is structured to support plug-in components
along with developer-provided rules, used at runtime to decide which component
best matches a given runtime environment.

150

Q. Huang et al.

The primary contributions of this work are the following:
– WAN collaboration requires sophisticated management of ﬁrewalls, bottleneck
links, organizational policy, and performance-driven protocol optimization.
Kevlar automates such tasks and shows that Web Services and peer-to-peer
protocols can co-exist in Internet WAN environments, despite the many complexities that arise from network conﬁgurations and performance limitations.
Kevlar illustrates a new and interesting form of runtime adaption, in which
a distributed application must determine which components to launch on the
basis of runtime criteria evaluated on a per-node basis.
– Kevlar applies the LO component model to replace the centralized features
of our Quilt system with a completely decentralized, gossip-based solution,
thus eliminating a central point of failure, as well as an additional performance bottleneck.
– We evaluate Kevlar across a range of experiments within a challenging
and complex network environment. In contrast to most popular Web-Service
architectures, as well as our prior Quilt system, neither of which deliver
acceptable or reliable performance in this scenario, Kevlar succeeds in its
design goals for eﬃcient collaborative applications.
The Kevlar system is distributed under a FreeBSD license, available for download and deployment from http://kevlar.cs.cornell.edu/. While the current
version scales to hundreds of simultaneous users, our ongoing work expands support to conﬁgurations with tens of thousands or hundreds of thousands of users.
To achieve such scalability, we are extending Kevlar’s multicast-forwarding
components to allow for pre-emptive ﬁltering of data during multicast. This capability would align Kevlar more closely with the needs of distributed virtual
worlds and online games and their high-volume, rich data streams: the server
need only send all the data once, for each client to receive an optimal, personalized subset of the complete stream. Further discussion of such extensions is
outside the scope of this work.

2

Background

In detailing the architecture of Kevlar, we will ﬁrst brieﬂy summarize the Live
Objects component model [5,16], upon which Kevlar is built. LO presents a
new kind of “live distributed object,” replicated at each node in the system. The
replicas can communicate among themselves with any choice of protocol, and
the ensemble together represents the actual live object. These live objects can
be composed as a graph, in which case, the replicas of each distinct live object
on a given node interact using a simple, but ﬂexible, event-based interface. Type
checking is employed both at design time and at run-time, and the type-checking
system itself is highly ﬂexible. For example, an LO representation of an airplane
might compose an airplane rendering object with an object that fault-tolerantly
captures location data from a GPS source, which in turn is composed with
a multicast protocol presented through an LO interface: a “data replication”

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

Service Collaboration (SC)

Kevlar (Kv)

Message
Buﬀer

Sync

Service LOs

Multicast Container
Multicast
Multicast Driver
Library
Multicast Driver

Communication Layer (CL)

Transmitter

SC

Multicast
Kv
Packet

Detector

151

CL

Network

Fig. 1. Architecture of a Kevlar-enabled LO application. Three major Live
Objects compose a demonstration application: Service Collaboration (SC), Kevlar
(KV), and Communication Layer (CL). As the application executes, all replicas of
each LO communicate with one another across the network.

object. The airplane might require protocols that support total ordering and
real-time delivery, and the type checker would have to verify that the associated
protocols oﬀer these properties (though the LO platform does not independently
ensure such claims are correct).
As mentioned earlier, LO includes a drag-and-drop application builder. Many
applications require little to no programming, simply using existing objects parameterized with URLs pointing to data sources. Additional objects simply implement a standard interface that we provide. This style of development would
be familiar to any Java or C# user familiar with graphical interface design. The
resulting LO application resides as an easily shared XML representation.
Figure 1 presents the architecture for a prototypical Kevlar application.
Here, Service Collaboration (SC), Kevlar (KV), and Communication Layer
(CL) live objects interface, on a given system node, through their respective
event-based interfaces. Inside each live object (such as SC), we ﬁnd a graph
composed by several service objects (e.g., maps, airplanes, weather, etc.). In a
distributed environment, the replicas for each service live object communicate
with other replicas of their type across the network, sharing content or synchronizing state. Meanwhile, the KV and CL objects provide multicast function and
real packet delivery on their own respective levels.
Prior work on the LO approach focused on type checking and event-driven interaction mechanisms [16] and eﬀorts to scale through multicore parallelism [17].
But the actual LO multicast protocols have thus far been simple, rather limited,
ones that operate only in enterprise data centers or other local-area networks
among groups of computers without intermediate ﬁrewalls or performance barriers. As a result, prior to this work, all LO demonstration applications have been
unsuitable for WAN deployment.

3

Patchwork Overlay in Kevlar

While Kevlar uses the LO component model, it also extends a more recent system of ours: Quilt distributed event-notiﬁcation [12]. As a free-standing library,
Quilt combines independent multicast patches for separate network regions into

152

Q. Huang et al.

Fig. 2. Patchwork overlay. Kevlar automates the construction of multicast overlays
across complex environments, with hosts in various local and wide-area networks. Here,
Kevlar combines a collection of regional multicast overlays (patches) into a single system-wide patchwork overlay, thus separating the multicast interface for the application
from the runtime-driven, performance-optimized implementation of the overlay.

.....

Local Topology

23 24 25 26 27 28 29 30 31 ... 34
List of
{t,l,h} triples

8

Max value (h)

7

Min value (l)

List of
{d,p} tuples

6

Performance
type (t)

Protocol (p)

Connectivity

5

Optional flag

Direction (d)

Type

4

Router Stack
(path of
routers to
local DNS)

EUID
Content

3

IPMC range

2

# of routers

1

|

0

|

|

Byte Oﬀset

Measured Performance

Fig. 3. EUID. Components of Kevlar’s Environmental Unique IDentiﬁer with accompanying byte oﬀset (bar atop number signiﬁes variable width of particular entry),
enumerating metrics for connectivity, local topology, and measured performance.

a single application-layer overlay across complex WAN settings. Figure 2 depicts this process for Kevlar, with a single overlay including WAN links and
connecting four independent local networks, each with its own multicast policies, ﬁrewall placement, and congestion proﬁle. As one might expect, there is no
single, simple solution that can operate optimally in all such settings.
A Kevlar application developer creates a set of multicast “drivers,” each consisting of a protocol implemented as an LO, and an associated rule describing the
conditions under which that protocol can be used. (The API for these driver rules is
that of Quilt [12].) As earlier shown in Fig. 1, Kevlar itself consists of a library into
which these drivers are linked. At initialization of a Kevlar application, the system proﬁles its local environment through a series of sophisticated measurements
and updates the performance measurements continually during runtime. The resulting metrics are aggregated as the “environmental unique identiﬁer” (EUID) in
Fig. 3, which is used for assignment of nodes to a particular patch.
During application initialization, Kevlar nodes send their EUIDs to a bootstrap server and obtain a list of other nodes that appear to be “close” to the node
with respect to the topology, latency, bandwidth, and protocol compatibility,
as indicated by the EUID. Unlike Quilt, which relies on a central server to

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

153

Kevlar node
1 EUID
Bootstrap
server

4 Join Patch

3 Gossip
2 Contacts

System membership
{1,2,3,4,5,6,7}

1

6

2

4
5

3
7

1
2

6
3

7

Fig. 4. Patch assignment. Upon initialization, a Kevlar node tests its local environment to produce an EUID; (1) sends this EUID to a bootstrap server; (2) receives
a contact list in return; (3) uses this list to identify other nearby members and patches
via gossip; (4) applies these EUID metrics to dynamically select patches to join.

incrementally construct and maintain the patchwork, Kevlar nodes create and
maintain patches in a peer-to-peer fashion. Quilt’s single point of failure is thus
eliminated, since the bootstrap functionality is trivial. This decentralized scheme
also improves security and privacy, as domains have the option of running protocols
and networking rules privately with no dependence on an external Quilt server.
In a further departure from Quilt, Kevlar runs a system-wide anti-entropy
gossip protocol [18] to exchange information about membership, EUIDs, and
patches that are formed, along with their identiﬁers and the protocols in use.
For our experiments, we set the gossip rate to one exchange per second. The
choice of a gossip recipient is biased towards proximate nodes, according to
the EUID information. More speciﬁcally, we compose a ﬁxed-length portion of
the EUID into a number that reﬂects protocol compatibility, presence on the
routing path (shorter routing paths are padded with zeros), average latency,
and bandwidth. We then deﬁne the approximate distance between two nodes
to be the absolute diﬀerence between these numbers mapped from their EUIDs;
thus the above order of composition reveals the priority of each component
in determining proximity and compatibility between end-hosts. In each gossip
round, we rank the recipients by the distance and select the recipient of rank
i with probability proportional to 2−i . This results in membership sets biased
toward nearby nodes; hence, updates in the node’s surrounding environment are
disseminated faster.
Kevlar seeks to maximize connectivity while relaying multicasts between
patches in a fault-tolerant manner. It also avoids duplicate event delivery, even
under node churn. Figure 4 illustrates patch formation and assignment logic
(details as in Quilt [12]).
The Kevlar multicast protocols used in this paper include:
1. IP multicast (IPMC) [7]. This protocol assigns a distinct IPMC class-D
multicast address to each region. The associated rule checks to make sure
that IP multicast is permitted by examining all network interfaces used by
each application, and testing their IPMC-enabled bit.

154

Q. Huang et al.

Fig. 5. Example application. This Kevlar demonstration, showcasing a searchand-rescue application, requires signiﬁcant communication traﬃc among cooperating
users at the network edge as well as constant query and retrieval of centralized data
objects.

2. DONet [21]. This protocol implements a mesh-structured application layer
multicast that uses TCP for the links. The actual content is disseminated
on a random-graph overlay maintained by a gossip protocol. It works in
the style of BitTorrent [6]: every node advertises its local content buﬀer
snapshot epidemically with a ﬁxed fanout; then, by the end of each scheduled
epoch, it solicits non-received data in a bandwidth-aware manner; once a
request is received, the node returns the associated data, also in a bandwidthaware manner. Kevlar uses DONet for physically close end-users without
IPMC support, since such users have lower latencies between them, varied
bandwidth capacities, and more churn than data center servers.
3. OMNI Tree [4]. The OMNI tree is a latency-optimized application layer
multicast (ALM) overlay, serving both multicast receivers and Multicast
Service Nodes (MSN), which are actually local proxies. Assuming MSN nodes
have negligible latency, the OMNI Tree optimizes the average root-to-client
latency based on the root-to-MSN latency and the number of clients each
MSN is serving, but with constrained outdegree between MSNs. Kevlar
uses OMNI Tree as the inter-patch protocol to sew diﬀerent patches together.
For fast and stable forwarding among regional patches, the associated rule
prefers nodes with accessible connections and high network performance.

4

Anatomy of a Kevlar Application

As a canonical demonstration of Kevlar, we implement a distributed searchand-rescue application which exercises almost all of the functionality described
above. Figure 5 depicts a representative user interface, displaying both centrally
hosted and edge objects and allowing for user manipulation of the scenario.
Such an application could readily be designed and assembled by a non-programmer, using pre-existing Live Objects (stored, for example, in a local or shared ﬁle

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

155

system) that each represent a diﬀerent piece of data: aircraft, ground vehicles,
rescue workers, weather information, maps, etc. The developer simply synthesizes the scenario from pertinent objects and associates them with their data
sources. Further changes to the application can be made at runtime, by any of
the users sharing the system (provided, of course, that they have appropriate
permissions). For instance, commanders may modify the positions of aircraft or
adjust the demographic statistics displayed on the interface. Components can
also be reused, even simultaneously: those involved in Fig. 5 could separately
participate in any other sort of Kevlar application.
The user accesses this application through its XML representation, which includes references to the “live folders” that hold content added at runtime. Thus,
the user interface can be viewed as a visualization of the theoretical “graph”
of program composition, expressed in its XML representation. While the overall
graph structure is determined by the original application designer, some portions
are, by design, extensible by other users at runtime: the live folders just mentioned, for example. The “leaves” of the graph are the airplanes, maps, weather,
etc. Some leaf objects extract and display content from cloud repositories, while
others use peer-to-peer protocols (for example, to track locations of moving objects). As the graph evolves (either through movement of objects, or their explicit
addition or deletion), the interface will automatically update in sync.
Much of the functionality behind this user interface requires communication,
using multicast channels established by Kevlar. These channels retrieve hosted
content, share edge updates, or coordinate or synchronize some other action.
For example, satellite imagery might be updated via multicast to all users as
a satellite over-ﬂies a region of interest. A ﬁrst responder in the ﬁeld could,
similarly, use a multicast group to share a status report on some disaster victims;
his unit commander could multicast orders to a larger rescue unit, and so forth.
The Kevlar runtime is implicitly launched through the execution of associated applications. As determined by the Kevlar application developer, a given
application includes some set of built-in multicast protocols (for our experiments
here, the three deﬁned in Sect. 3). For each node and multicast group, Kevlar
determines the appropriate protocols to launch and helps these protocols form
initial peering relationships with other members of a given node’s patch. Beyond
this, each protocol maintains its own peer structure. Thus, where IPMC is permitted and other peers are also present, Kevlar will launch the IPMC protocol
modules and provide them with class-D multicast addresses as parameters, as
well as a few contacts for initialization. Using an OMNI network, Kevlar will
sew this IPMC region together with other remote regions: Kevlar will launch
the OMNI protocol and help the module peer with appropriate remote nodes. On
nodes that run both OMNI and IPMC protocols, Kevlar will help relay multicasts between them, minimizing the risk of network partition through redundant
dual-protocol nodes, while simultaneously suppressing the duplicate delivery of
updates. If failures occur or nodes quit the overlay, Kevlar orchestrates the
repair of the mesh, all in a fully decentralized manner.

156

Q. Huang et al.

Fig. 6. Network topology. Experimental network topology, as emulated on DETERlab, with data centers and an Internet service provider: node numbers, latencies, and
data rates as indicated, with IP multicast internally enabled in data centers.

5
5.1

Evaluation
Experiment Setup

The remainder of this paper presents an experimental evaluation of our Kevlar
system in a number of distinct application scenarios.
We ﬁrst explore the ability of Kevlar, compared to other multicast protocols,
to establish an eﬃcient overlay topology and minimize latencies from a single given
sender to the ensemble of receivers. Further, we investigate the bandwidth utilization in such a topology, comparing Kevlar to the native OMNI Tree and DONet
protocols, as well as to a pure IP multicast (which, of course, might not actually
be a legal choice in settings where Kevlar is launched, but represents something
of an ideal when permitted). We explore a number of various simple application
scenarios, each characterized by a set of input traﬃc parameters of ﬁxed message
size and data rate; these tests reveal the applications for which Kevlar’s quality of service determination yields improved results. We continue our systematic
exploration of Kevlar’s performance for complex real-time collaborative applications by considering the needs of the search-and-rescue application discussed
earlier, and illustrated in Fig. 5. Finally, we conclude our evaluation by examining the robustness of Kevlar to recover from catastrophic failure cases.
We rely upon DETERlab [8], an Emulab [20] environment, to construct our
experimental environment and establish a network topology that includes various
types of local subnets. In total, we use 80 nodes, distributed among three diﬀerent
regions and connected across an emulated Internet backbone. As shown in Fig. 6,
the regions consist of: (1) a large data center whose internal LAN has three layers
of depth to its hierarchy; (2) a smaller data center with a 2-layer LAN; and (3) a
consumer ISP, remote from big data center but topologically near the small one;
the ISP supports consumers via various last-mile access technologies (including
cable, DSL, and satellite, each with appropriate latency, jitter, and bandwidth
constraints). IP multicast is enabled inside data centers, but unusable for home

CDF (per-message mean) [%]

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

100
80

157

Kevlar
IPMC
OMNI
DONet

60
40
20
0
0
10

10

1

2

10
Delivery time [ms]

10

3

10

4

Fig. 7. Delivery latency. Cumulative distribution function (CDF) of the latency for a
given data-center sender to contact some percentage of all other nodes (in experimental
topology in Fig. 6), for each of four competing protocols: mean computed over ten
messages; Kevlar closely tracks IPMC except for the ﬁnal 15% of the nodes (which,
as part of the ISP, cannot access IPMC), where it instead uses the bandwidth-eﬃcient,
but higher-latency, DONet protocol.

users. Bandwidth and latency settings accompany Fig. 6. The object of this
topology is to accurately mimic a portion of the real Internet, including some
large data centers hosting the primary server farm and working in concert with
small data centers distributed around the world to provide low-latency support
for nearby users.
Unless otherwise speciﬁed, all data points correspond to an average over ten
trials. Error bars are calculated as one sample standard deviation but omitted
from ﬁgures when too small to be clearly visible.
5.2

Examination of Overlay Topology

We ﬁrst examine the raw performance of Kevlar along with the various alternative protocols in the overlay topology without the inﬂuence of particular
traﬃc patterns of any speciﬁc application. We accomplish this measurement by
sending a series of small messages (10-Byte payloads) at low data rates (100
messages per second), so that the available bandwidth across the links and data
transfer delays do not aﬀect these results.
Finding low-latency paths. First, we evaluate the eﬃciency of each protocol
in matching its overlay to the actual physical network topology. Any eﬃcient
multicast service should identify fast delivery pathways to each receiver irrespective of the application traﬃc input. Figure 7 shows just such a comparison
among IPMC, DONet, OMNI Tree, and Kevlar — the latency for a sender to
send data to all the receivers in the experiment environment. Here, and in the
ensuing sections, we use the cumulative distribution function (CDF) to display
many of our measurements; the structure of many of the dissemination patterns

158

Q. Huang et al.

Table 1. Forwarding load. Comparison of the skew in load among four competing
protocols, demonstrating both the average forwarding load per system node, as a percentage of the traﬃc stream, as well as the number of nodes that forward traﬃc, among
all eighty system nodes. With network hardware support, IPMC requires only a single
forwarding node, while OMNI Tree and DONet must rely on many intermediate nodes.
Kevlar nodes generally only forward one-ﬁfth of the packets they receive.
Protocol
IPMC
Kevlar
OMNI Tree
DONet

Load per node [%]
1.3
20.3
100.0
102.8

Forwarding nodes [#]
1
12
20
66

incorporate bursts of traﬃc, such that the associated probability density function
(PDF) would be ﬁlled with spikes that are diﬃcult to interpret visually.
A number of qualitative observations emerge from Fig. 7. First, we note that
our Kevlar multicast protocol is closest to what IPMC oﬀers (recall that IPMC
is generally unavailable in a real WAN deployment, hence it represents an ideal,
but one that may not be an actual option). Both show a largely stair-stepped
CDF that corresponds to (1) low-latency communication in the large data center
from which the sending traﬃc originates; (2) fast transfer to the smaller data
center; and (3) ﬁnal delivery to small, remote ISP. We also note the diﬀerentiation
between Kevlar and IPMC for delivery to the ﬁnal 15% of nodes, located in
the remote ISP; this is due to the lack of IPMC among the ISP customers
(which therefore receive no IPMC traﬃc), and Kevlar’s reliance there on the
underlying DONet protocol (which utilizes bandwidth better than OMNI Tree
for such end-host users). To understand the performance of the OMNI Tree
protocol, we must recall that it cannot, by design, leverage IPMC even within
the data centers where it is available and must instead build its own tree structure
to disseminate data. This consumes time and thus accounts for CDF values that
are universally lower than (or equal to) that of IPMC (and Kevlar, again by
design). Finally, we see that DONet is the least capable of the protocols in
creating an eﬃcient overlay. As explained above in Sect. 3, DONet’s protocol
uses only “pull” semantics (rather than “push” in the other protocols) and this
introduces signiﬁcant latency to identify the node location that possesses the
required data. DONet’s use of epochs and timers only exacerbates this problem
(though, in general, as we see later, the use of epochs has some beneﬁts in
enabling better bandwidth utilization).
Forwarding load on overlay nodes. Recall that some intermediate nodes in
an ALM may need to bear the burden of forwarding packets to other receivers.
We explore the eﬃciency of overlay formation for the multicast protocols by
examining the average volume of traﬃc that each node in the overlay needs to
transmit to distribute a given stream, as a fraction of the total traﬃc volume.

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

159

Table 1 shows this amount of traﬃc that must be forwarded by an average
overlay node, as well as the number of nodes that forward packets. With IPMC,
only a single sender needs to forward packets, so, on average, nodes transmit
only a fraction (1/80) of the stream. As expected, the OMNI Tree and DONet
protocols do not beneﬁt from network-level multicast and thus the typical node
must forward every packet received. Kevlar is second to IPMC in performance:
an average node forwards 20% of packets; this indicates that Kevlar is able to
exploit IPMC where supported and to use an ALM (DONet) otherwise.
5.3

Performance of Simple Applications

This section focuses upon the realized delivery performance among a number
of applications with simple, ﬁxed traﬃc patterns. Speciﬁcally, we measure the
performance with respect to ﬁfteen diﬀerent ensembles of traﬃc streams, each
with diﬀerent ﬁxed values for message size (150, 1500, and 15 000 Bytes) and data
rate (100 kbps, 300 kbps, 1 Mbps, 3 Mbps, and 10 Mbps). As mentioned before,
these streams represent ﬁve diﬀerent levels of media production: standard-quality
audio MP3, network video conferencing, Video CD (VCD), standard-deﬁnition
(SD) IP Television (IPTV), and high-deﬁnition (HD) IPTV [11]. In each scenario,
we contrast the four protocols in terms of their CDF, determined by message
delivery times averaged across ten measurements.
Figure 8 shows our results, here. We make three primary qualitative observations from this series of measurements: The ﬁrst point is that all of these
subﬁgures show the same qualitative structure for each protocol, considered independently, as we found in the application-agnostic evaluation from Fig. 7.
We would expect as much — the qualitative features of the performance, for a
particular application (with a given ﬁxed data rate and message size) using a
speciﬁc multicast protocol, are largely determined by the corresponding overlay.
However, for each particular application, the curves for the individual protocols show various oﬀsets in time as well as dilation or contraction of features in
time. Next, for delivery to a large fraction ( 90%) of the receivers, Kevlar
shows identical (ideal) performance when compared to IPMC within all application scenarios. For dissemination to the ﬁnal fraction of nodes (those within the
ISP), Kevlar out-performs DONet in all cases, while it exceeds OMNI Tree
only for 15 000-Byte messages at 10 Mbps (see Fig. 8(d)). Lastly, we observe
no qualitative distinctions among the measurements conducted at data rates of
100 kbps, 300 kbps (for either message size) and those of 1 Mbps (additional
tests at 3 Mbps and for 150 Byte messages gave identical results). Thus, due to
space constraints, we do not reproduce the former in Fig. 8.
We now separately examine the behavior of each protocol within the same
measurements conducted above, and previously shown in Fig. 8. This allows
us to discuss more subtle distinctions in protocol performance at varying data
rate and message size parameterization, that are otherwise not apparent above.
Figure 9 presents a comparison of the IPMC, OMNI Tree, DONet, and Kevlar
protocols for diﬀerent application domains (diﬀerent ﬁxed input parameters).

Q. Huang et al.

100
80

Kevlar
IPMC
OMNI
DONet

CDF (per-message mean) [%]

CDF (per-message mean) [%]

160

60
40
20
0
0
10

10

1

2

3

10
10
Delivery time [ms]

10

4

10

80

Kevlar
IPMC
OMNI
DONet

60
40
20
0
100

101

102
103
Delivery time [ms]

104

105

(c) 10 Mbps with 1500-Byte Message

Kevlar
IPMC
OMNI
DONet

60
40
20

10

1

2

3

10
10
Delivery time [ms]

10

4

10

5

(b) 1 Mbps with 15 000-Byte Message
CDF (per-message mean) [%]

CDF (per-message mean) [%]

100

80

0
0
10

5

(a) 1 Mbps with 1500-Byte Message

100

100
80

Kevlar
IPMC
OMNI
DONet

60
40
20
0
100

101

102
103
Delivery time [ms]

104

105

(d) 10 Mbps with 15 000-Byte Message

Fig. 8. Performance of simple applications (input traﬃc dependence). Performance comparison of multicast protocols for input traﬃc of various message size and
data rate: each subﬁgure, corresponding to a diﬀerent set of input parameter values,
shows the CDF (per-message mean as in Fig. 7) of message delivery time. Space constraints preclude visualization of the remaining eleven experiments (speciﬁcally, data
rates of 100 kbps, 300 kbps and 3 Mbps, and message size of 150 Bytes), with nearly
identical results.

Two quantitative observations emerge: In contrasting data rates of 1 and
10 Mbps (for all message sizes), we note that the curves representing IPMC,
Kevlar, and DONet protocols are completely unaﬀected by data rate considerations. (In fact, such curves identically overlap each other, to the extent that we
remove such extra labels within each subﬁgure to increase legibility.) Conversely,
the OMNI Tree protocol collapses with increasing data rates: the curves for the
higher rates are shifted to the right in time by factor of ratio between rates (10
in ﬁgure). The impact of data rate on OMNI Tree is suitably severe that its
performance for smaller messages at higher data rates (1500 Bytes at 10 Mbps)
is worse (or equal, at times) than that for larger messages at lower data rates
(15 000 Bytes at 1 Mbps). We conjecture that this eﬀect is due to the ineﬃciency
of bandwidth utilization by the OMNI Tree protocol.
We also contrast message sizes of 150, 1500, and 15 000 Bytes for all data
rates and note a key qualitative diﬀerence: The curves for IPMC, Kevlar, and
OMNI Tree protocols are all shifted to the right by an order of magnitude in

100

150
1.5k
15k

CDF (per-message mean) [%]

CDF (per-message mean) [%]

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

80
60
40
20
0
0
10

10

1

2

3

10
10
Delivery time [ms]

10

4

10

80
60
40
20

150
1.5k
15k

80
60
40
20
0
100

101

102
103
Delivery time [ms]

(c) DONet protocol

10

1

2

3

10
10
Delivery time [ms]

10

4

10

5

(b) OMNI Tree protocol
CDF (per-message mean) [%]

CDF (per-message mean) [%]

(a) IPMC protocol
100

150 1M
150 10M
1.5K 1M
1.5K 10M
15k 1M
15k 10M

100

0
0
10

5

161

104

105

100

150
1.5k
15k

80
60
40
20
0
100

101

102
103
Delivery time [ms]

104

105

(d) Kevlar protocol

Fig. 9. Performance of simple applications (protocol dependence). Performance comparison of multicast protocols for input traﬃc of various message size and
data rate: each subﬁgure, corresponding to a diﬀerent protocol, shows the CDF of delivery time. (Note, for protocols with data-rate independent results, only message size
is shown.)

time, while DONet is signiﬁcantly less aﬀected by this variation in message size
parameter. This observation follows trivially due to the need to transfer larger
amounts of data to the receivers. The smaller correlation between message size
and DONet performance can be explained by DONet’s parallelization of data
transfers for small portions of each message amongst many nodes (within each
epoch that it deﬁnes).
Finally, Fig. 10 extracts the performance trends from the raw data presented in
Figs. 8 and 9. Now, for each of the four multicast protocols studied, we consider the
time required to distribute application traﬃc to various cumulative subsets of the
entire environment. Thus, the family of curves for each protocol is comprised of
three separate curves, which represent the delivery to diﬀerent cumulative values
(10%, 50%, and 90%) of the total node population; increasing color saturation of
each curve in the family denotes more complete dissemination of traﬃc.
This ﬁgure further conﬁrms many of the trends we discussed above: (1) strong
dependence on input traﬃc data rate for OMNI Tree; (2) correlation between
input message size and delivery time for IPMC, Kevlar, and OMNI Tree (weak
for DONet); and (3) for IPMC and Kevlar protocols, the faster relative increase

Q. Huang et al.

Kevlar
IPMC
OMNI
DONet

6

10

5

10

4

Time (for cumulative delivery) [ms]

Time (for cumulative delivery) [ms]

162

10

3

10

2

10

1

10

100
-1

10

-2

10

-3

10

Kevlar
IPMC
OMNI
DONet

6

10

5

10

4

10

3

10

2

10

1

10

100
-1

10

-2

10

-3

100

300

1000
3000
Data rate [kbps]

(a) 1500-Byte message size

10000

10

100

300

1000
3000
Data rate [kbps]

10000

(b) 15 000-Byte message size

Fig. 10. Overall trends for simple application delivery. Performance of multicast protocols for transmission of various traﬃc streams (each with ﬁxed message size
and data rate) associated with diﬀerent video delivery standards. Subﬁgures show distinct message sizes (1500 and 15 000 Bytes, respectively), and, as a function of data
rate, each plots the time required to distribute messages to cumulative subsets of the
entire environment: the three separate curves, in each protocol family, display the time
corresponding to diﬀerent cumulative values (10%, 50%, and 90% delivery in the corresponding CDFs of Fig. 8). Space constraints preclude display of third subﬁgure with
ﬁve additional curves, associated with 150-Byte packets at all ﬁve possible data rates.

(more vertical CDF) in distribution for 15 000-Bytes messages as compared to
1500-Byte messages; this is seen in the narrower spacing within a given family
of curves in Fig. 10(a) as compared to Fig. 10(b).
5.4

Performance of a Complex Application

Above, we have just evaluated the performance for a few simple, model applications that exhibit constant traﬃc patterns with ﬁxed message size and data rate.
Now, we expand upon such an evaluation by discussing the performance implications from diverse traﬃc patterns of a type associated with more complicated
applications, focusing on the search and rescue application discussed in Sect. 2.
In Fig. 11, the inset depicts the input traﬃc pattern for this scenario. It plots
message size as a function of time over the 10 minute period of application execution and communication. (We note that the data rate, here, is a secondary feature based upon the density of messages in time; however, we present the data in
this manner, rather than as a 2D histogram, so as to reveal the time correlations
of data, which would be absent in the histogram presentation.) This input ﬁgure
depicts various traﬃc patterns generated by users’ operations: during the start
up, the collaborative application requires a checkpoint of existing service objects,
generating a burst of messages followed by low traﬃc during local resource initialization; after a short time, users are able to explore the world map and add
or remove new services of their choosing, all resulting in bulk transfers of texture
contents from the data center; after fetching all the needed data, communications
among users are steady and moderate, primarily at the network edge.

10

8

10

7

Kevlar
IPMC
OMNI
DONet

106
10

5

10

4

10

3

Message size [Bytes]

Time (for cumulative delivery) [ms]

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

163

6000
4000
2000
0
0

2
4
6
8
Traffic pattern [min]

10

102
10

1

100

0

1

2

3

4

5

6

7

8

9

10

Traffic pattern [min]

Fig. 11. Performance of a complex collaborative application. Performance for
multicast protocols while executing a complex collaborative application: inset shows
the varying input traﬃc pattern of the application, with message size as a function of
the position in time in the pattern. For each protocol, the main panel displays a family
of curves plotting the time required to distribute messages to cumulative subsets of
the entire environment, as a function of position in the input traﬃc pattern (increasing
color saturation corresponds to cumulative delivery as in Fig. 10).

The main panel of Fig. 11 shows the resulting performance for each protocol in this scenario. We ﬁrst compute CDFs associated with all four protocols,
for each of the (dozens of) individual sample points — representing a distinct
value of data rate and message size — as seen in the inset of Fig. 11. From each
of these CDFs, we then extract the time for the protocols to achieve diﬀerent
cumulative distributions of 10%, 50%, and 90%. Figure 11 thus shows four families of curves, one for each of the protocols, with each family diﬀerentiating the
behavior associated with various completion levels in the dissemination of data.
Here, increasing saturation levels of each curve color denote more completion of
traﬃc distribution.
We make four observations, here: (1) Kevlar tracks IPMC very closely, for
all completion levels up to, but not including 90%. This reﬂects Kevlar’s underlying usage of IPMC within both data centers, its need for DONet in the
non-IPMC-enabled ISP, and its use of a small-sized OMNI Tree for sewing its
multicast patches together. (2) Throughout this experiment, across all varying
message sizes and data rates, OMNI Tree shows a consistent performance penalty
of approximately 400%. (3) DONet is the slowest of the protocols here, requiring
seconds for the traﬃc to arrive at a signiﬁcant fraction of the receivers. Indeed,
its performance is degraded 100-fold, compared to both IPMC and Kevlar;
as discussed above, this primarily results from the its inclusion of a handshake
scheme, an epoch-based time line, and a “pull”-based communication pattern.
However, in fairness to DONet, we recognize that its performance variance upon
varying data rate is signiﬁcantly lower that that of OMNI Tree; this meets its
design goal to optimize for bandwidth utilization instead of latency. (4) Finally,

164

Q. Huang et al.

Throughput [%]

100
80
60
40
Kevlar
IPMC
OMNI
DONet

20
0
35

40

45
Time [s]

50

55

Fig. 12. Robustness under failure. Robustness of the various multicast protocols
upon fail-stop (at 40 seconds) of a random 50% of the nodes during transmission
of 1500-Byte messages at 1 Mbps data rate: ﬁgure plots percentage throughput to
remaining live nodes relative to the throughput prior to failures, as a function of time.

we examine the diﬀerence in time for each protocol to achieve 50% versus 90%
cumulative distribution of traﬃc: First, we note that DONet shows little diﬀerence between these curves; we expect as much from previous measurements (see
Fig. 8) in which the DONet curves show very abrupt transitions from negligible completion to almost total distribution of traﬃc. Conversely, IPMC, OMNI
Tree, and Kevlar all show an approximate 5-fold increase in time required to
reach 90% of receivers compared to that needed to deliver to 50% of receivers.
Lastly, we note that Kevlar’s relative performance with respect to the ideal
of IPMC is not as strong for delivery to 90% of nodes as it is for 50%; this
is due to Kevlar’s reliance upon non-IPMC underlying protocols for its ISP
transmission as compared to its dissemination within each data center.
5.5

Robustness

We conclude our evaluation by considering the robustness of Kevlar in contrast to other multicast protocols. To obtain this measurement, we introduce
catastrophic failures in a large portion of the nodes within our environment and
monitor the resulting recovery for each multicast protocol. Speciﬁcally, we select the scenario from Sect. 5.3 with 1500-Byte messages sent at a data rate of
1 Mbps; after steady, non-perturbed communication for 40 seconds, we fail-stop
a random selection of 50% of the nodes. (To ensure that each protocol confronts
the identical failure scenario, we perform the random selection of nodes only
once, and then reuse the same choice of failed nodes for the measurements of all
the diﬀerent protocols.) In quantifying the robustness of each system, we compute the percentage throughput received by the remaining live nodes relative to
the amount before onset of node failures.

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

165

Throughput [%]

100
80
60
40
20

Kevlar
Quilt (with bootstrap)
Quilt (without bootstrap)

0
35

40

45
Time [s]

50

55

Fig. 13. Kevlar’s improvement in robustness over Quilt. Comparison of robustness of Kevlar’s distributed patchwork maintenance against Quilt patchwork implementations, both with and without centralized bootstrap servers (same scenario as in
Fig. 12). Kevlar shows a 100% improvement in recovery time versus Quilt with bootstrap servers; without bootstrapping, Quilt never recovers from the failure scenario.

Figure 12 depicts the robustness results for this measurement. We immediately observe that IPMC performs ideally, showing no loss of throughput. All
other protocols suﬀer a dramatic reduction in throughput as their overlays are
disturbed by node failures; this is to be expected for ALMs, in contrast to physical IPMC. We observe that the OMNI Tree protocol has the largest loss of
throughput; this likely results from the failure of high-level (root) nodes in its
tree structure that then disrupt delivery to all the nodes in their sub-hierarchy.
Recovery of OMNI Tree is relatively quick, though; its event-driven rejoin procedure reconstructs the tree overlay faster than DONet’s epoch-style protocol
recovers its overlay. We also observe that OMNI Tree shows ﬂuctuations in its
recovery as it is attempting to simultaneously optimize its structure for latency
considerations while new nodes are also rejoining the overlay. The DONet ALM
is slower to recover than OMNI Tree; however, since traﬃc load is balanced
across its nodes, DONet throughput does not ever decrease as dramatically as
that of OMNI Tree. Finally, we consider Kevlar and observe that it outperforms both OMNI Tree and DONet in terms of robustness: Kevlar maintains
higher throughput than either other ALM, as it can still utilize the underlying IPMC protocol in patches were it is available. Further, Kevlar recovers as
quickly as the OMNI Tree protocol. Finally, during recovery, Kevlar’s throughput monotonically increases, unlike the ﬂuctuations during OMNI Tree’s overlay
reconstruction.
We perform one additional measurement to quantify Kevlar’s enhanced
robustness. In Fig. 13, we contrast Kevlar against two diﬀerent versions of
our Quilt [12] protocol, as introduced in Sect. 1 above. Here, we include Quilt
both with and without its use of a bootstrap server. In the centralized Quilt
framework, we observe that the bootstrap system assures recovery, at a cost of

166

Q. Huang et al.

increased recovery time due to greater load on a few central bootstrap servers.
Kevlar’s use of distributed patch maintenance shows at least a 100% improvement in recovery time compared with Quilt.
5.6

Summary of Measurement Evaluation

We now summarize our measurements and observations from this section: we
showed that Kevlar empirically achieves a performance envelope matching
our design goals articulated earlier. The Kevlar system consistently leveraged
whichever protocol was most eﬃcient among those available in each topological
network patch. Obviously, if IPMC were available in all situations, simply using
IPMC might be the best plan. But when IPMC is not available, Kevlar is a
very practical and eﬀective alternative.

6

Related Work

Kevlar’s object-oriented design was inspired by Quality Objects (QuO) [3,19].
The QuO middleware provides quality-of-service information to allow programs
to function reasonably well on WANs and LANs. During run-time, QuO applications may alter modes, between “safe,” “overloaded,” or “graceful shutdown,”
causing objects to change their behavior accordingly.
We are unaware of technologies, other than Kevlar and Quilt that use environmentally aware patchwork overlays for multicast. Patchwork overlays for
other purposes, however, have been proposed: A large-scale routing system,
MONET [2], groups together diﬀerent kinds of client links into “patches” to
allow IP packets to traverse NATs and ﬁrewalls and to optimize ineﬃcient
application-level routing paths. Similarly, OCALA [13] accommodates legacy
applications over modern network architectures by combining diﬀerent overlays
to reach disadvantaged network hosts.

7

Conclusions

Kevlar delivers a ﬂexible architecture for creating collaborative applications
that can be eﬃciently utilized in the wide-area Internet. The system encourages modular extension and facilitates development of sophisticated applications
through composition of distributed objects to form graphs, within which object
instances interact by event-passing.
Typical users of collaborative applications, such as virtual reality platforms
and massively multiplayer online games, are subject to quite non-uniform Internet environments. Thus, runtime adaptation is required to appropriately conﬁgure these deployed applications. Indeed, Kevlar automates selection and
activation of the correct component out of a set of functionally similar options,
each optimized for diﬀerent conditions.

Kevlar: A Flexible Infrastructure for Wide-Area Collaborative Applications

167

Kevlar innovates at several levels: through its ﬂexible and modular architecture; through the mechanisms used to select appropriate components; and through
the optimization-driven decision layers that create the desired distributed infrastructure. This structure controls what might otherwise be a very complex system.
A careful evaluation shows that Kevlar really does function as designed.
Acknowledgments. We are grateful to the Chinese National Science Foundation (Project No. 60731160630), National Science Foundation, Air Force
Research Laboratory, EU IST Project CoMiFin (FP7-ICT-225407/2008), Intel
Corporation, and Cisco Systems for their support of this research.

References
1. Alonso, G., Casati, F., Kuno, H., Machiraju, V.: Web Services Concepts, Architectures and Applications. Springer, Heidelberg (2004)
2. Andersen, D.G., Balakrishnan, H., Kaashoek, M.F., Rao, R.N.: Improving Web
Availability for Clients with MONET. In: Proc. of NSDI 2005, Boston, MA, USA
(2005)
3. Atighetchi, M., Pal, P.P., Jones, C.C., Rubel, P., Schantz, R.E., Loyall, J.P., Zinky,
J.A.: Building Auto-Adaptive Distributed Applications: The QuO-APOD Experience. In: Proc. of ICDCSW 2003, Washington, DC, USA (2003)
4. Banerjee, S., Kommareddy, C., Kar, K., Bhattacharjee, B., Khuller, S.: Construction of an eﬃcient overlay multicast infrastructure for real-time applications. In:
Proc. of INFOCOM 2003, San Francisco, CA, USA (2003)
5. Birman, K., Cantwell, J., Freedman, D., Huang, Q., Nikolov, P., Ostrowski, K.:
Edge Mashups for Service-Oriented Collaboration. IEEE Computer 42(5), 90–94
(2009)
6. Cohen, B.: Incentives Build Robustness in BitTorrent, Tech. Report (2003)
7. Deering, S.E., Cheriton, D.R.: Multicast routing in datagram internetworks and
extended LANs. ACM Trans. Comput. Syst. 8(2), 85–110 (1990)
8. DETERlab, http://www.isi.deterlab.net/
9. Feng, W.-c., Brandt, D., Saha, D.: A Long-Term Study of a Popular MMORPG.
In: Proc. of NetGames 2007, Melbourne, Australia (2007)
10. Google Voice and Video Chat, http://www.google.com/chat/video/
11. HDV Speciﬁcation, http://www.avchd-info.org/format/
12. Huang, Q., Vigfusson, Y., Birman, K., Li, H.: Quilt: A Patchwork of Multicast
Regions. In: Proc. of DEBS 2010, Cambridge, UK (2010)
13. Joseph, D., Kannan, J., Kubota, A., Lakshminarayanan, K., Stoica, I., Wehrle, K.:
OCALA: An Architecture for Supporting Legacy Applications over Overlays. In:
Proc. of NSDI 2006, San Jose, CA, USA (2006)
14. Leighton, T.: Improving Performance on the Internet. Commun. ACM 52(2), 44–51
(2009)
15. Miller, F.P., Vandome, A.F., McBrewster, J.: Second Life. Alpha Press (2009)
16. Ostrowski, K., Birman, K., Dolev, D., Ahnn, J.H.: Programming with Live Distributed Objects. In: Vitek, J. (ed.) ECOOP 2008. LNCS, vol. 5142, pp. 463–489.
Springer, Heidelberg (2008)

168

Q. Huang et al.

17. Ostrowski, K., Sakoda, C., Birman, K.: Self-Replicating Objects for Multicore Platforms. In: D’Hondt, T. (ed.) Proc. of ECOOP 2010. LNCS, vol. 6183, pp. 452–477.
Springer, Heidelberg (2010)
18. van Renesse, R., Minsky, Y., Hayden, M.: A Gossip-Based Failure Detection Service. In: Proc. of Middleware 1998, The Lake District, UK (1998)
19. Vanegas, R., Zinky, J.A., Loyall, J.P., Karr, D., Schantz, R.E., Bakken, D.E.: QuO’s
runtime support for quality of service in distributed objects. In: Proc. of Middleware 1998, The Lake District, UK (1998)
20. White, B., Lepreau, J., Stoller, L., Ricci, R., Guruprasad, S., Newbold, M., Hibler, M., Barb, C., Joglekar, A.: An Integrated Experimental Environment for
Distributed Systems and Networks. In: Proc. of OSDI 2002, Boston, MA, USA
(2002)
21. Zhang, X., Liu, J., Li, B., Yum, T.-S.P.: CoolStreaming/DONet: a data-driven
overlay network for peer-to-peer live media streaming. In: Proc. of INFOCOM
2005, Miami, FL, USA (2005)

