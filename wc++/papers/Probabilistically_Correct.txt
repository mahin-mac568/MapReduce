A Probabilistically Correct Leader Election
Protocol for Large Groups
Indranil Gupta, Robbert van Renesse, and Kenneth P. Birman
Cornell University, Ithaca, NY 14850, USA
{gupta, rvr, ken}@cs.cornell.edu

Abstract. This paper presents a scalable leader election protocol for
large process groups with a weak membership requirement. The underlying network is assumed to be unreliable but characterized by probabilistic failure rates of processes and message deliveries. The protocol
trades correctness for scale, that is, it provides very good probabilistic
guarantees on correct termination in the sense of the classical speciﬁcation of the election problem, and of generating a constant number of
messages, both independent of group size. After formally specifying the
probabilistic properties, we describe the protocol in detail. Our subsequent mathematical analysis provides probabilistic bounds on the complexity of the protocol. Finally, the results of simulation show that the
performance of the protocol is satisfactory.
Keywords: Asynchronous networks, process groups, leader election,
fault-tolerance, scalable protocols, randomized protocols.

1

Introduction

Computer networks are plagued by crashing machines, message loss, network
partitioning, etc., and these problems are aggravated with increasing size of the
network. As such, several protocol speciﬁcations are diﬃcult, if not impossible,
to solve over large-scale networks. The speciﬁcations of these protocols, which include reliable multicast, leader election, mutual exclusion, and virtual synchrony,
require giving strong deterministic correctness guarantees to applications. However, in results stemming from the famous Impossibility of Consensus proof by
Fischer-Lynch-Paterson [8], most of these problems have been proved to be unsolvable in failure-prone asynchronous networks. Probabilistic and randomized
methodologies are increasingly being used to counter this unreliability by reducing strict correctness guarantees to probabilistic ones, and gaining scalability in
return. A good example of such a protocol is the Bimodal Multicast protocol
[1], an epidemic protocol that provides only a high probability of multicast delivery to group members. In exchange, the protocol gains scalability, delivering
messages at a steady rate even for large group sizes.


This work was funded by DARPA/RADC grant F30602-99-1-6532 and in part by
the NSF grant No. EIA 97-03470.

Apps

Protocols with strong semantics
- Leader election, mutual exclusion,
Virtual Synchrony

*

Large no of members

* Probabilisitic / deterministic
correctness
*

Scalability

*

Probabilistic reliability

Bimodal multicast
* Scalability

Underlying network

*

Error-prone, unreliable

Fig. 1. Target Setting.

Our current work is targeted toward realizing similar goals for the important
class of protocols that classically have been formulated over reliable multicast
message delivery. We envision a world where applications would run over a new
class of probabilistic protocols (Figure 1) and receive probabilistically guaranteed services from the layer below. By virtue of the proposed approach, these
applications would scale arbitrarily, while guaranteeing correctness with a certain minimal probability even in the face of an unreliable network. For example,
these protocols could be used to build a replicated ﬁle system with probabilistic
guarantees on consistency.
As a step towards this goal, this paper presents a probabilistic leader election
protocol. Leader election arises in settings ranging from locking and synchronization to load balancing [12] and maintaining membership in virtually synchronous
executions [13]. The classical speciﬁcation of the leader election problem for a
process group states that at the termination of the protocol, exactly one nonfaulty group member is elected as the leader, and every other non-faulty member
in the group knows about this choice. In this paper, we show that, given probability guarantees on point-to-point (unicast) and multicast message delivery,
process failure rates, and multicast group view content, our protocol gives a
very high probability of correct termination. In return, it gains on the scalability: with very high probability, the protocol involves only a constant number of
messages regardless of group size. We also show how to augment our protocol
to adapt to changing failure probabilities of the network (w.r.t. processes and
messages).
Sabel and Marzullo [20] proved that leader election over a failure-prone asynchronous network is impossible. This and a variety of other impossibility results
all stem from the FLP result [8], which proves that there is no protocol by which
an asynchronous system of processes can agree on a binary value, even with only
one faulty process.
To provide a taxonomy of the complexity of the class of consensus protocols,
Chandra and Toueg [4] proposed extending the network with failure detectors.

However, the leader election problem can be solved if and only if a perfect
failure detector is available - one that suspects no alive processes, and eventually
suspects every faulty one [20]. [6] discusses several weakened system models
and what types of consensus are possible in these models, while [7] presents a
weakened asynchronous model which assumes that message deliveries are always
time-bounded. Since “real” systems lack such guarantees, these results have been
valuable mostly in a theoretical rather than a practical sense.
Non-randomized leader election algorithms for a failure-prone asynchronous
network model broadly fall into the following ﬂavors. 1) Gallager-Humblet-Spiratype algorithms [9, 17] that work by constructing several spanning trees in the
network, with a prospective leader at the root of each of these, and recursively
reduce the number of these spanning trees to one. The correctness guarantees
of these algorithms are violated in the face of pathological process and message
failures. 2) Models that create logical partitions in the network when communication becomes unreliable, each logical partition electing one leader [7]. This
approach does not solve the scalability problem but circumvents it. 3) Models
that involve strong assumptions such as, for example, that all (process) failures
occur before the election protocol starts [22], or that all messages are delivered
reliably [3].
Probabilistic solutions to leader election in general networks are usually classiﬁed as randomized solutions to the consensus problem [5], but these focus on
improving either the correctness guarantee [19], or the bound on the number
of tolerated failures [23]. The (expected or worst case) message complexities in
these algorithms are typically at least linear in the group size, and fault tolerance is usually guaranteed by tolerating process failures up to some fraction of
the group size. Further, most of these protocols involve several rounds of O(N )
simultaneous multicasts to the group (where N is the group size), and this can
cause deterioration of the delivery performance of the underlying network.
Our take on the leader election problem is in a more practical setting than
any of the above cited works. We are motivated by practical considerations of
scaling in a real network where failures can be characterized by probabilities. The
spirit of our approach is close to that of [1] and [24]. Our protocol’s probabilistic
guarantees are similar to those of leader election algorithms for the perfect information model [14, 25], while our guarantee on the number of messages resembles
that of [11], which presents an election protocol for anonymous rings. To the
best of our knowledge, ours is the ﬁrst protocol that trades correctness of the
leader election problem for better scalability.
The analysis and simulation of our protocol will assume a network model
where process failures, and message delivery latencies and statistics have identical, independent and uniform distributions. Before doing so, however, we suggest
that the leadership election algorithm proposed here belongs to a class of gossip
protocols, such as Bimodal Multicast [1], where such a simpliﬁed approach leads
to results applicable in the real world. Although the model used in [1], like the
one presented here, seems simpliﬁed and unlikely to hold for more than some
percentage of messages in the network, one ﬁnds that in real-world scenarios,

even with tremendous rates of injected loss, delay, and long periods of correlated
disruption, the protocol degrades gracefully in its probabilistic guarantees.
The rest of the paper is organized as follows. Section 2 describes the assumed
model and statement of the election problem we solve. Section 3 describes the
protocol in detail. Section 4 analyses the protocol mathematically, while Section 5
presents simulations results. In Section 6, we present our conclusions.

2
2.1

The Model and Problem
Model

In our model, all processes have unique identiﬁers (e.g., consisting of their host
address and local process identiﬁer). All processes that might be involved in
the election are part of a group, which can have an arbitrarily large number of
members. Each process has a possibly incomplete list of other members in the
group, called the process’ view. A process can communicate to another process
in its view by ucast (unicast, point-to-point) messages, as well as to the entire
group by mcast (multicast) messages.
Processes and message deliveries are both unreliable. Processes can undergo
only fail-stop failures, that is, a process halts and executes no further steps.
Messages (either ucast or mcast) may not be delivered at some or all of the
recipients. This is modeled by assuming that processes can crash with some
probability during a protocol round and a ucast (mcast) message may not reach
its recipient(s) with some probability. Probabilistically reliable multicast can be
provided using an epidemic protocol such as Bimodal Multicast [1]. The Bimodal
multicast protocol guarantees a high probability of multicast message delivery
to all group members in spite of failures by having each member periodically
gossip undelivered multicasts messages to a random subset of group members in
its view.
A few words on the weak group model are in order. As we deﬁne them, views
do not need to be consistent across processes, hence a pessimistic yet scalable
failure detection service such as the gossip heartbeat mechanism of [24] suﬃces.
New processes can join the group by multicasting a message to it, and receiving
a reply/state transfer from at least one member that included it in its view.
Our analysis later in this paper assumes a uniform distribution for process
failure probabilities (pf ail ), ucast/mcast message delivery failure probabilities
(pucastl /pmcastl ), as well as the probability that a random member has another
random member in its view, which we call the view probability (view prob).
2.2

Problem Statement

An election is initiated by an mcast message. This might originate from, say, a
client who wants to access a database managed by the group, or one or more
member(s) detecting a failure of a service or even the previous leader. In our
discussion, we will assume only one initiating message, but the extension of our
protocol to several initiating messages is not too diﬃcult.

In classical leader election, after termination there is exactly one non-faulty
process that has been elected leader, and all non-faulty processes know this
choice. In probabilistic leader election, with known high probability,
– (Uniqueness) there is exactly one non-faulty process that considers itself the
leader;
– (Agreement) all non-faulty group members know this leader; and
– (Scale) a round of the protocol involves a total number of messages that can
be bounded independent of the group size.

3

Probabilistic Leader Election

This section describes the proposed leader election protocol. The protocol consists of several rounds, while each round consist of three phases. In Section 3.1,
we present the phases in a round. In Section 3.2, we describe the full protocol
and present its pseudo-code.
3.1

Phases in a Round of the Protocol

Filter Phase We assume that the initiating mcast I is uniquely identiﬁed by a
bit string AI . For example, AI could be the (source address, sequence number)
pair of message I, or the (election #, round #) pair for this election round. Each
group member Mi that receives this message computes a hash of the concatenation of AI and Mi ’s address, using a hash function H that deterministically maps
bit strings to the interval [0, 1]. Next, Mi calculates the filter value H(Mi AI )×Ni
for the initiating message, where Ni is the size of (number of members in) Mi ’s
current view. Mi participates in the next phase of this round, called the Relay
Phase, if and only if this ﬁlter value is less than a constant K; otherwise it waits
until the completion of the Relay phase. We require that H and K be the same
for all members. We show in Section 4 that for a good (or fair) hash function
H, large total number of group members N , the probability that the number of
members throughout the Relay phase lies in an interval near K, quickly goes to
unity at small values of K. This convergence is independent of N and is dependent only on the process failure, message delivery failure and view probabilities.
If the Ni ’s are the same for all members, each member Mi can calculate the
set of members {Mj }i in its view that will satisfy the ﬁlter condition. It does so
by checking if H(Mj AI ) × Ni < K for each member Mj in its view. In practice,
the Ni ’s may diﬀer, but this will not cause the calculated set {Mj }i to diﬀer
much from the actual one. (A more practical approach is to use an approximation
of the total number of group members for Ni . This can be achieved by gossiping
this number throughout the group. Thus, Ni ’s of diﬀerent members will be close
and the above ﬁlter value calculation will be approximately consistent.)
Figure 2 shows an illustration of one protocol round. The initiating multicast
I is multicast to the entire group, but some group members may not receive it
since mcast delivery is unreliable. The ones who do receive it evaluate the ﬁlter
condition in the next step. The members labeled with solid circles (2, 3, N ) ﬁnd
this condition to be true and hence participate in the Relay phase.

Group
I

1

2

3

4

N-1

N

Initiating Mcast I
Hash(I,self)*N < K
Hash(I,self)*N >= K
Relay Phase
(among filter members)

Relay Phase members
mcast elected leaders

Failure Detection
Phase

Fig. 2. One (Successful) Protocol Round.

Relay Phase As explained earlier, a member Mi that has passed the ﬁlter and
is participating in the Relay phase can calculate the subset of members {Mj }i
in its view that would have passed the ﬁlter condition if they received I. In
the Relay phase, Mi ﬁrst sends ucast messages to all such members in the set
{Mj }i specifying Mi ’s preferred choice for a leader from among its view members.
This choice is determined by the ordering generated by a choice function which
evaluates the advantages of a particular member being elected leader. We require
no restriction on the particular choice functions used, although all members need
to use the same choice function in evaluating their preferred leaders, breaking
ties by choosing the process with a lower identity. A good choice function would
account for load, location, network topology, etc. [21].
Second, whenever Mi is contacted by another member Mk in a similar manner, it includes Mk in its view (and adds it to {Mj }i ), and compares Mk ’s choice
with its own. If Mk ’s choice is “better” than its own according to the choice function, Mi relays this new choice to all the members in the set {Mj }i by ucast
messages, and replaces its current best choice for leader. Otherwise, Mi replies
back to Mk specifying its current best leader choice.
In the example of Figure 2, the 2nd , 3rd and N th group members enter the
Relay phase, but the 2nd member subsequently fails. If either of the 3rd and
the N th members has the other in its view, they will be able to exchange relay
messages regarding the best leader.
Consider the undirected graph with nodes deﬁned by the set of members
participating in the Relay phase (relay members), and an edge between two
members if and only if at least one of them has the other in its view throughout
the phase. We call this the relay graph. Assuming timely message deliveries and
no process failures, each connected component of this graph will elect exactly
one leader, with a number of (ucast) messages dependent only on the size of
the component. In Sections 4 and 5, we show that for a good hash function, the
likelihood of the relay graph having exactly one component (and thus electing
exactly one leader in the Relay Phase), approaches unity quickly at low values of
K. Further, this convergence is independent of N and is dependent only on the

process failure, message delivery failure and view probabilities. In Section 5, for
an example choice function that is widely used in many distributed systems, we
show that message delivery and process failures do not aﬀect this convergence.
Note that the number of ucast messages exchanged in a Relay phase with m
members is O(m3 ), since each relay member’s best choice might be communicated to every other relay member.
Finally, at the end of the Relay phase, when each component has decided
on one leader, each member Mi participating in the Relay phase multicasts the
identiﬁer of the leader selected by Mi ’s component (Mi ’s current best choice) to
the entire group—this is the set of final multicasts of this election round. The
total number of multicast messages in the Relay phase is thus O(m). Since it is
likely that m lies in an interval near the protocol parameter K which is chosen
regardless of N (analysis of Section 4), this implies only a constant number of
ucast and mcast messages in the Relay Phase with high probability, regardless
of the value of N .
In the example of Figure 2, once the 3rd and N th members have agreed on
a leader, each of them multicasts this information to the group. Some of the
group members may not receive both multicasts, but it is unlikely that every
non-faulty member will receive neither.

Failure Detection Phase Consider a situation in which there is more than one
connected component in the relay graph. Each of these components may select
and multicast diﬀerent leaders in the Relay phase. Having each Relay phase
member broadcast its component’s selected leader to the entire group using a
probabilistic multicast mechanism (such as Bimodal Multicast [1]) would give
us a high probability that this inconsistency is detected by some group member
(which need not have participated in the Relay phase). If a member detects
an inconsistency such as two leaders elected in the same round, it immediately
sends out a multicast to the entire group re-initiating the next election round.
If no member detects any such inconsistency, the election protocol round would
satisfy the Uniqueness and Agreement conditions of Section 2.2 if and only if
there was exactly one component in the Relay phase, this component selected
exactly one leader, every other non-faulty group member received at least one
of the multicast messages specifying this selected leader, and this elected leader
did not fail during the election round.
To reduce the probability of many group members sending out a (re-)initiating
multicast message at the same time, we could have each member Mi calculate the
hash (using H) of its own id concatenated with the message identiﬁer of one of
the resulting messages, and send out a re-initiating multicast only if this is lower
than K/Ni . This would again give an expected constant number of re-initiating
multicasts. Alternatively, we could use a randomized delay before sending the
request: if a process receives a re-initiation request, it need not send one of its
own.

Member Mi ::Election (Sequence, RoundN um):
1. On receiving “Init election” message I specifying (Sequence, RoundN um),
select K from RoundN um using strategy
if H(Mi AI ) × Ni < K, go to step 2
else wait for timeout period T ime Out 1 (time for step 2 to complete) and jump to step 3
2. Find the set of members {Mj }i in my view such that H(Mj AI ) × Ni < K
find best preferred leader in my view and send this using ucast messages to members in {Mj }i
do until T ime Out 2
receive similar preferred leader messages for this (Sequence, RoundN um) from
other members Mk
include Mk in {Mj }i and Mi ’s view
compare current best leader choice with Mk ’s preference (using choice function)
if Mk ’s preference better,
update current best leader choice and send ucast messages to all members in {Mj }i
specifying this
else
inform Mk using a ucast of Mi ’s current best choice
wait T ime Out 3 to receive everyone’s final leader choice.
3. if received none or more than one leader as final choice,
choose one of the final choice messages F
if H(Mi AF ) × Ni < K,
multicast an initiating message I  specifying (Sequence, RoundN um + 1)
wait for T ime Out 3, increment RoundN um and jump to step 1
if no re-initiating mcast received within another T ime Out 3,
declare received choice as elected leader and include it in Mi ’s view
else increment RoundN um and jump to step 1.

Fig. 3.

3.2

The Complete Election Protocol.

General Protocol Strategy

Figure 3 contains the pseudo-code for the steps executed by a group member Mi
during a complete election protocol, each distinct election speciﬁed by a unique
sequence number SequenceN um. Our complete election protocol strategy is to
use the election round described in the previous section as a building block
in constructing a protocol with several rounds. A complete protocol strategy
speciﬁes 1) the value of K to be used (by each member) in the ﬁrst round of
each election, 2) the value of K to be used in round number l + 1 as a function of
the value of K used in round l, and 3) a maximum number of rounds after which
the protocol is aborted. Note that this strategy is deterministic and known to
all members, and is not decided dynamically. In Figure 3, RoundN um refers to
the current round number in this election. Mi :: Election(SequenceN um, 1) is
called by Mi on receipt of the initiating message for that election protocol.
As we will see in Section 4, the initial value of K can be calculated from the
required protocol round success probability, view probabilities, process and message delivery failure probabilities for the network in which the group members
are based, and the total maximum number of group members. Unfortunately, in
practice, failure probabilities may vary over time. Since a higher value of K leads
to a higher probability of success in a round (Section 4), we conclude that round
l +1 must use a higher value of K than round l. For example, one could use twice
the value of K in round l, for round l + 1. This class of strategies make our leader

election protocol adaptive to the unpredictability of the network. Note that a
low maximum number of protocol rounds implies fewer expected messages while
a higher value results in a better probability of correct termination.
The pseudo-code of Figure 3 has the members using time-outs (the T ime Out ∗
values) to detect (or, rather, estimate) completion of a particular part of the protocol round in an asynchronous network.1 T ime Out 2 is the expected time for
termination of the Relay phase (before the ﬁnal multicasts at the end). This is
just the worst case propagation and processing delay needed for a message containing a relay member’s initial preferred leader to reach all other relay members
(if it is not lost by a process or link failure). Although the number of relay members is not known a priori, we show in Section 4 that with known high probability,
the number of relay members who do not fail until the end of the Relay phase
is at most (3K/2). Thus T ime Out 2 can be taken to be the product of (3K/2)
(the maximum length of any path in a relay graph with 3K/2 members) and
the maximum propagation and processing delay for a ucast packet in the underlying network. T ime Out 3 is just the worst case time for delivery of a mcast
message. In the Bimodal multicast protocol [1], this would be the maximum
time a message is buﬀered anywhere in the group. T ime Out 1 is the sum of the
maximum time needed at member Mi to calculate the set {Mj }i , and the values
of T ime Out 2 and T ime Out 3. Also, a member ignores any messages from
previous protocol rounds or phases, and “jumps ahead” on receiving a message
from a future protocol round or phase.

4

Analysis - Properties of the Protocol

In this section, we summarize the analysis of the probability of success, detection
on incorrect termination and message and time complexity of a round of our
protocol. Detailed discussions and proofs of the results are available in [10].
Let N be the number of group members at the start of the election round - we
will assume that this value is approximately known to all group members so that
the ﬁlter value calculation is consistent across members. Let view prob be the
probability of any member Mi having any other member Mk in its view throughout the election round. Let pf ail , pucastl , pmcastl be the failure probabilities of a
process during an election round, a ucast message delivery, and a mcast message
delivery, respectively. The protocol round analyzed uses the parameter K as in
Figure 2. We denote the terms ((1−pmcastl )·K) and ((1−pf ail )·(1−pmcastl )·K)
as K1 and K2 respectively.
For simplicity, we assume that the probabilities of deliveries of a mcast message at diﬀerent receivers are independent, as well as that the T ime Out ∗ values
in the protocol of Figure 2 are large enough. Our analysis can be modiﬁed to
omit the latter assumption by estimating the T ime Out ∗ values from K and the
worst-case propagation and processing delays for ucast and mcast messages (as
1

Although an asynchronous network model does not admit real time, in practice
timers are readily available, and we do not assume any synchronization nor much in
the way of accuracy in measuring intervals.

described in Section 3.2), and redeﬁning pucastl (pmcastl ) to be the failure probabilities of a ucast (mcast) message delivery within the corresponding worst-case
delays, as well as calculating view prob, pf ail for a round duration. We also
assume that the hash function H used is fair, that is, it distributes its outputs
uniformly in the interval [0, 1]. For a particular hash function (e.g., the one described in [15]), we would need to know its distribution function and plug it into
a similar analysis.
Consider the following events in an election round with parameter K:
E1: between K1 /2 and 3K1 /2 members are chosen to participate in the Relay
phase, and between K2 /2 and 3K2 /2 relay members do not fail before sending
out the ﬁnal multicast;
E2: the set of relay members who do not fail before their ﬁnal multicasts form a
connected component in the relay graph throughout the Relay phase;
E3: at the end of the Relay phase, each non-faulty relay member has selected
the same leader;
E4: by the end of the election round, each group member either fails or receives
at least one of the ﬁnal multicast messages (specifying the selected leader) from
each component in the relay graph at the end of the Relay phase;
E5: the elected leader does not fail.
Theorem 1 (Round success probabilities):
(a) The event [E3, E4, E5] in an election round in the protocol of Figure 2 implies
that it is successful, that is, the election satisﬁes the Uniqueness and Agreement
properties of Section 2.2.
(b) From [2, 16], the probability of success in an election round with parameter
K can be lower bounded by
Pr[E1, E2, E3, E4, E5]
= Pr[E1] · Pr[E2|E1] · Pr[E3|E1, E2] · Pr[E4|E1, E2, E3] · Pr[E5|E1, E2, E3, E4].


2
2
−K1 /8
−K2 /8
e
−
2
)
≥
(1 − 2 πK
πK2 e
1
·(e−

K2
2

(1−view prob)

K2
−1
2

) · ((1 − pf ail ) · (1 − pucastl )3K2 /2−1 )
K /2

2
))N ) · (1 − pf ail )
·((pf ail + (1 − pf ail )(1 − pmcastl

¾

Figure 4 shows the typical variation of the lower bounds (subscript lb stands
for “lower bound”) of the ﬁrst four product terms and Prlb [E1, E2, E3, E4, E5],
for values of K up to 65, with (view prob, pmcastl , pucastl , pf ail , N )
= (0.4, 0.01, 0.01, 0.01, 10000). The quick convergence of Prlb [E1] and Prlb [E2|E1]
to unity at small K (here  40) is independent of the value of N . In fact,
Prlb [E4|E1, E2, E3] is the only one among the ﬁve factors of Prlb [E1, E2, E3, E4, E5]
that seems to depend on N . However, its value remains close to unity for

−K /2

K /2

2
2
N · pmcastl
 1, or N  pmcastl
, which, for K = 40, turns out as 1039 , a
number beyond the size of most practical process groups.

1.2

Pr_{lb}[E1]
Pr_{lb}[E2|E1]
Pr_{lb}[E3|E1,E2]
Pr_{lb}[E4|E1,E2,E3]
Pr_{lb}[E1,..,E5]

Probability

1

0.8

0.6

0.4

0.2

0
10

20

30

40
K

50

60

70

Fig. 4. Pessimistic Analysis of Success Probability of one round of our Leader Election
Protocol.

Thus, for all practical values of initial group size N , the minimum probability
that an election round of the protocol of Figure 2 satisﬁes the Uniqueness and
Agreement conditions is dependent only on the failure and view probabilities in
the group, but is independent of N .
From Figure 4, this minimal protocol round success probability appears to
peak at 0.6 for the above parameters. This is because our estimate for
Prlb [E3|E1, E2] is very pessimistic in assuming a weak global view knowledge,
and thus including the possibility that all the initially preferred leaders in the
Relay phase might be distinct. In a practical setting however, a fair number of
the m (non-faulty) relay members would have the same initial leader choices (eg.,
if the choice function preferred a candidate leader with lower identity), so the
probability Prlb [E3|E1, E2] (and hence Prlb [E1, E2, E3, E4, E5]) would be much
higher than the curve shows. The simulation results in Section 5 conﬁrm this for
the choice function mentioned above.
Theorem 2 (Detection of incorrect termination in a round): Pr[ a reinitiating mcast is sent out to the group or all group members fail by the end
of the round | election round with parameter K does not succeed ] is bounded
below by Prlb [E1] · (1 − (1 − (1 − pf ail )(1 − pmcastl )3K2 /2 )N ).
Note that, with K ﬁxed so that the term Prlb [E1] is arbitrarily close to unity,
the probability of detection of incorrect election in a round of the presented pro¾
tocol goes to unity as N tends to inﬁnity.

Theorem 3 (Round message complexity): With (high) probability Prlb [E1]
((Prlb [E1])2 ), the number of ucast (mcast) messages in an election round is
O(K 3 ) (O(K)) (since K1 , K2 are both O(K)). Also, with (high) probability
(Prlb [E1])2 , the number of simultaneous multicasts in the network anytime dur¾
ing the round is O(K).
Theorem 4 (Round message complexity): Further, the expected number of
ucast (mcast) messages in a round of the protocol is O(K 3 ) (O(K)). This is
O(1) when K is ﬁxed independent of N . The suggested election protocol round
thus achieves the optimal expected message complexity for any global agreement
¾
protocol on a group of size N .
Theorem 5 (Round time complexity): With (high) probability (Prlb [E1])2 ,
the time complexity of an election round is O(N K + N ) for a group of size N
over a network with N nodes. This is O(N + N ) for K ﬁxed independent of N ,
¾
which is the optimal time complexity for any global agreement protocol.

5

Simulation Results

In this section, we analyze, through simulation, the performance of an election
protocol strategy from the class described in Section 3.2. The correctness, scalability and fault tolerance of the proposed protocol are more evident here than
from the pessimistic analysis of Section 4. The strategy we analyze is speciﬁed
by 1) an initial (ﬁrst round) parameter Kinit = 7; 2) for l ≤ 4, the value of K in
round l is twice the value used in round l − 1; and at l = 5, K = N ; and ﬁnally
3) the election protocol aborts after 5 rounds. The protocol is initiated by one
mcast to the group, which initially has N members.
The unreliability of the underlying network and process group mechanism
is characterized by the parameters pucastl , pmcastl , pf ail , view prob as deﬁned in
Section 4. The hash function is assumed to be a fair one. The choice function used
in the simulation is the simple one that prefers candidates with lower identities.
The metrics used to measure the performance of the protocol are the following. P(Success) evaluates the ﬁnal success probability of the protocol, and
appears in two forms. “Strong” success probability refers to the (average) probability that a protocol run satisﬁes the Uniqueness and Agreement conditions.
“Weak” success probability is in fact the (average) majority fraction of the nonfaulty group members that agree on one leader at the end of the protocol. This
is a useful metric for situations where electing more than one leader may be allowed, such as [18]. # Rounds refers to the average number of rounds after which
the protocol terminates, either successfully, or without detecting an inconsistent
election, or because the maximum number of rounds speciﬁed by the strategy
has been reached. # Messages refers to the average number of ucast and mcast
messages generated in the network during the protocol.
Figure 5 shows the results from the simulations. This ﬁgure is organized with
each column of graphs indicating the variation of a particular performance metric

as a function of each of the system parameters, and each row of graphs showing
the eﬀect of varying a system parameter on each of the performance metrics.
Each point on these plots is the average of results obtained from 1000 runs of
the protocol with the speciﬁed parameters. In Figures 5(a-c), pucastl = pmcastl
is varied in the range [0, 0.5] for ﬁxed N = 2000, pf ail = 0.001, view prob = 0.5.
The graphs for varying pf ail are very similar and not included here. In Figures
5(d-f), N is varied in the range [1000, 5000] for ﬁxed pf ail = 0.001, view prob =
0.5, pucastl = pmcastl = 0.001. In Figures 5(g-i), view prob is varied in the range
[0.2, 0.5] for N = 5000, pf ail = 0.001, pucastl = pmcastl = 0.001.
Figures 5(a,d,g) show the very high success probability (strong) guaranteed
by the above strategy even in the face of high message loss rates (up to pucastl =
pmcastl = 0.4, up to and beyond N = 6000 and view prob = 0.2). Notice that
even the “weak” success ratio is close to 1 for these ranges, and as expected,
is higher than the strong success probability. Figures 5(b,e,h) show the time
scalability of the protocol for the same ranges of parameters that produced
high success probabilities. Note Figure 5(e), which shows termination within 1
expected round for values of N up to 6000 (!) group members. Figures 5(c,f,i)
show the message scalability for the same variation of parameters. Note again
the lack of variation in the expected number of messages exchanged (Figure 5(f))
as N is varied up to 6000 members.
Figures 5(a-c) display the level of fault tolerance the protocol possesses with
respect to message failures. Figures 5(d-f) show how much our protocol scales
even as the number of group members is increased into the thousands. Finally,
Figures 5(g-i) show that our protocol performs well even in the presence of only
partial membership information at each member.

6

Conclusions

This paper described a novel leader election protocol that is scalable, but provides only a probabilistic guarantee on correct termination. Mathematical analysis and simulation results show that the protocol gives very good probabilities of
correct termination, in the classical sense of the speciﬁcation of leader election,
even as the group size is increased into the tens of thousands. The protocol also
(probabilistically) guarantees a low and almost constant message complexity independent of this group size. Finally, all these guarantees are oﬀered in the face
of process and link failure probabilities in the underlying network, and with only
a weak membership view requirement.
The trade-oﬀ among the above guarantees is determined by one crucial protocol parameter–the value of K in an election round. From the simulation results,
it is clear that choosing K to be a small number (although not very small) sufﬁces to provide acceptable guarantees for the speciﬁed parameters. Increasing
the value of K would enable the protocol to tolerate higher failure probabilities,
but would increase its message complexity. Varying K thus yields a trade-oﬀ
between increasing the fault tolerance and correctness probability guarantee on
one hand and lowering the message complexity on the other.

Acknowledgements We wish to thank the anonymous referees for their suggestions in improving the quality of the paper and its presentation.
10

Strong
Weak

1000

800

#Messages: ucast and mcast

8
0.9

#Rounds

P(Success): Strong and Weak

ucast
mcast

900

1

0.8

6

4
0.7

700
600
500
400
300

2

0.6

200
100

0.5
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5

0
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5

p_ucastl=p_mcastl

0
0.10.150.20.250.30.350.40.450.5

p_ucastl=p_mcastl

p_ucastl=p_mcastl

Fig (a). P(Success) vs message loss

Fig (b). Avg. #Rounds vs message

Fig (c). Avg. #Messages vs mes-

probability.

loss probability.

sage loss probability.

10

Strong
Weak

30

ucast
mcast

1
25

#Messages: ucast and mcast

#Rounds

P(Success): Strong and Weak

8
0.9

0.8

6

4
0.7

20

15

10

2

0.6

0.5

5

0
1

1.5

2

2.5

3

3.5

4

4.5

5

0
1

1.5

N (1000’s)

Fig (d). P(Success) vs # Group

2

2.5

3

3.5

4

4.5

5

1

1.5

N (1000’s)

3

3.5

4

4.5

5

Fig (f). Avg. #Messages vs # Group

members.

members.

10

Strong
Weak

2.5

N (1000’s)

Fig (e). Avg. #Rounds vs # Group

members.

2

140

1

ucast
mcast

120

#Messages: ucast and mcast

#Rounds

P(Success): Strong and Weak

8
0.9

0.8

6

4
0.7

100

80

60

40

2

0.6

20

0.5
0.2 0.25 0.3 0.35 0.4 0.45 0.5

0
0.2

0.25

view_prob

0.3

0.35

0.4

0.45

0.5

0
0.2 0.25 0.3 0.35 0.4 0.45 0.5

view_prob

view_prob

Fig (g). P(Success) vs view prob- Fig (h). Avg. #Rounds vs view

Fig (i). Avg. #Messages vs view

ability.

probability.

probability.

Fig. 5. Performance characteristics of our Leader Election Protocol

References
1. K.P. Birman, M. Hayden, O. Ozkasap, Z. Xiao, M. Budiu, Y. Minsky, “Bimodal
multicast”, ACM Trans. Computer Systems, vol. 17, no. 2, May 1999, pp. 41-88.
2. B. Bollobas, A. Thomason, “Random graphs of small order”, Annals of Discrete
Mathematics, Random Graphs ’83, vol. 8, 1983, pp. 47-97.
3. J. Brunekreef, J.-P. Katoen, R. Koymans, S. Mauw, “Design and analysis of dynamic leader election protocols in broadcast networks”, Distributed Computing,
vol. 9, no. 4, Mar 1997, pp. 157-171

4. T.D. Chandra, S. Toueg, “Unreliable failure detectors for asynchronous systems”,
Proc. 10th Annual ACM Symp. Principles of Distributed Computing, 1991, pp.
325-340.
5. B. Chor, C. Dwork, “Randomization in Byzantine agreement”, Advances in Computing Research, vol. 5, 1989, pp. 443-498.
6. D. Dolev, C. Dwork, L. Stockmeyer, “On the minimal synchronism needed for
distributed consensus”, JACM, vol. 34, no. 1, Jan 1987, pp. 77-97.
7. C. Fetzer, F. Cristian, “A highly available local leader election service”, IEEE
Trans. Software Engineering, vol. 25, no. 5, Sep-Oct 1999, pp. 603-618.
8. M.J. Fischer, N.A. Lynch, M.S. Paterson, “Impossibility of distributed consensus
with one faulty process”, Journ. of the ACM, vol. 32, no. 2, Apr 1985, pp. 374-382.
9. R. Gallager, P. Humblet, P. Spira, “A distributed algorithm for minimum weight
spanning trees”, ACM Trans. Programming Languages nd Systems, vol. 4, no. 1,
Jan 1983, pp. 66-77.
10. I. Gupta, R. van Renesse, K.P. Birman, “A probabilistically correct leader
election protocol for large groups”, Computer Science Technical Report
ncstrl.cornell/TR2000-1794, Cornell University, U.S.A., Apr. 2000.
11. A. Itai, “On the computational power needed to elect a leader”, Lecture Notes in
Computer Science, vol. 486, 1991, pp. 29-40.
12. C.-T. King, T.B. Gendreau, L.M. Ni, “Reliable election in broadcast networks”,
Journ. Parallel and Distributed Computing, vol. 7, 1989, pp. 521-540.
13. C. Malloth, A. Schiper, “View synchronous communication in large scale networks”, Proc. 2nd Open Workshop of the ESPRIT project BROADCAST, Jul 1995.
14. R. Ostrovsky, S. Rajagopalan, U. Vazirani, “Simple and eﬃcient leader election in
the full information model”, Proc. 26th Annual ACM Symp. Theory of Computing,
1994, pp. 234-242.
15. O. Ozkasap, R. van Renesse, K.P. Birman, Z. Xiao, “Eﬃcient buﬀering in reliable
multicast protocols”, Proc. 1st Intnl. Workshop on Networked Group Communication, Nov. 1999, Lecture Notes in Computer Science, vol. 1736.
16. A. Papoulis, Probability, Random Variables, and Stochastic Processes, McGrawHill International Edition, 3rd edition, 1991.
17. D. Peleg, “Time optimal leader election in general networks”, Journ. Parallel and
Distributed Computing, vol. 8, no. 1, Jan, 1990, pp. 96-99.
18. R. De Prisco, B. Lampson, N. Lynch, “Revisiting the Paxos algorithm”, Proc.
11th Intnl. Workshop on Distributed Algorithms, 1997, Lecture Notes in Computer
Science, vol. 1320, pp. 111-125.
19. M.O. Rabin, “Randomized Byzantine generals”, Proc. 24th Annual Symp. Foundations of Computer Science, Nov. 1983, pp. 403-409.
20. L.S. Sabel, K. Marzullo, “Election vs. consensus in asynchronous systems”,
Computer Science Technical Report ncstrl.cornell/TR95-1488, Cornell University,
U.S.A., 1995.
21. S. Singh, J.F. Kurose, “Electing good leaders”, Journ. Parallel and Distributed
Computing, vol. 21, no. 2, May 1994, pp. 184-201.
22. G. Taubenfeld, “Leader election in the presence of n-1 initial failures”, Information
Processing Letters, vol. 33, no. 1, Oct 1989, pp. 25-28.
23. S. Toueg, “Randomized Byzantine agreements”, Proc. 3rd Annual ACM Symp.
Principles of Distributed Computing, 1984, pp. 163-178.
24. R. van Renesse, Y. Minsky, M. Hayden, “A gossip-style failure detection service”,
Proc. Middleware ’98 (IFIP), Sept 1998, pp. 55-70.
25. D. Zuckerman, “Randomness-optimal sampling, extractors, and constructive leader
election”, Proc. 28th Annual ACM Symp. Theory of Computing, 1996, pp. 286-295.

